{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import gym\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import Box2D\n",
    "#from Box2D.b2 import (edgeShape, circleShape, fixtureDef, polygonShape, revoluteJointDef, contactListener)\n",
    " \n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.utils import colorize, seeding, EzPickle\n",
    "from PIL import Image, ImageDraw\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discretization\n",
    "possible_actions = np.array(list(product([-1,  0,  1], [-1,  0,  1], [-1,  0,  1], [-1,  0,  1])))\n",
    "env = gym.make(\"BipedalWalker-v2\")\n",
    "\n",
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-1554cc2729c5>:20: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/bcharyyev/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-6-1554cc2729c5>:25: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.random.categorical instead.\n"
     ]
    }
   ],
   "source": [
    "#Policy Network:\n",
    "#Specify the network architecture\n",
    "#Build the neural network\n",
    "#Select a random action based on the estimated probabilities\n",
    "#Define the training scheme \n",
    "#Run the policy for 1000 steps before training.\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# 1. Specify the network architecture\n",
    "n_inputs = env.observation_space.shape[0]  # == 24\n",
    "n_hidden = 10\n",
    "n_outputs = len(possible_actions) # == 625\n",
    "initializer = tf.variance_scaling_initializer()\n",
    "\n",
    "# 2. Build the neural network\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_inputs])\n",
    "\n",
    "hidden = tf.layers.dense(X, n_hidden, activation=tf.nn.selu, kernel_initializer=initializer)\n",
    "logits = tf.layers.dense(hidden, n_outputs, kernel_initializer=initializer)\n",
    "outputs = tf.nn.softmax(logits)\n",
    "\n",
    "# 3. Select a random action based on the estimated probabilities\n",
    "action_index = tf.squeeze(tf.multinomial(logits, num_samples=1), axis=-1)\n",
    "\n",
    "\n",
    "# 4. Training\n",
    "y = tf.one_hot(action_index, depth=len(possible_actions))\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=logits)\n",
    "optimizer = tf.train.AdamOptimizer(0.01)\n",
    "grads_and_vars = optimizer.compute_gradients(cross_entropy)\n",
    "gradients = [grad for grad, variable in grads_and_vars]\n",
    "gradient_placeholders = []\n",
    "grads_and_vars_feed = []\n",
    "for grad, variable in grads_and_vars:\n",
    "    g_placeholder = tf.placeholder(tf.float32, shape=grad.get_shape())\n",
    "    gradient_placeholders.append(g_placeholder)\n",
    "    grads_and_vars_feed.append((g_placeholder, variable))\n",
    "training_op = optimizer.apply_gradients(grads_and_vars_feed)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD8CAYAAAB9y7/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABtRJREFUeJzt3e1100gAhlFlD02sKCNuI2WAy9hDGV7KoI2kDEQZ3j9LcOz4K/qYmVf3/oIYgTjMPJ5IY/Gw3+87APL8VfoEAJiHwAOEEniAUAIPEErgAUIJPEAogQcIJfAAoQQeINSn0ifQdV03DJ2P0wIc6fvuYczxVvAAoQQeIJTAA4QSeIBQVdxkBbhF319+fRiWOY9WCDxQjWsB5z4CD0ymZKCt3k8JPPCqxRW0sJ8n8BCixTiPJe6XCTxUYo2B/ihhv43Aw0QEehnifjuBhxsJOK0ReIoRTO5h5X4/gZ+QYME8xP1jPKpgQgYhTGsYzKsxBH5iBiNMw1waT+BnYGDCOObQNAR+JgYofIy5Mx2Bn5Hrh3Af82VaAr8AgxYusxiah8AvxOCF95kb8xH4BRnI8JY5MS+BX5gBDS7JLEXgCzC4gSUIfEEizxoZ98sR+MIMdtbCd67LE/gKGPSkM8bL8DTJSvyeAJ5ISRJhL8sKvjImBCmM5fIEvkImBjAFga+UyNMqN1PrIfAVM0lojTFbFzdZK+fmKy0Q9jpZwTfCBKJWxma9BL4hJhK1MSbrJvCNMaGohbFYP4FvkIlFacZgG9xkbZSbr5Qg7G2xgm+cCcdSjLX2CHwAHyxhbsZXmwQ+iEnIHIyrdgk8cJa4t81N1jBuvjIFYc9gBR/KBOWjjJ0cAh/MzVfuZbxkEfgVMGm5hXGSR+BXwuTlEuMjk8CviEnMMZfxstlFszLDYIdNawSYjxL4FbKVcnoiTI0EfsXWtJoXYNZI4FeupsiLMExL4Lnrko0IQzsEnlfiDVlskwQIJfAAoQQeIJTAA4QSeIBQAg8QSuABQgk8QCiBBwgl8AChBB4glMADhBJ4gFACDxBK4AFCCTxAKIEHCCXwAKEEHiCUwAOEEniAUAIPEErgAUIJPEAogQcIJfAAoQQeIJTAA4QSeIBQAg8QSuABQgk8QCiBBwgl8AChBB4glMADhBJ4gFACDxBK4AFCCTxAKIEHCCXwAKEEHiCUwAOEEniAUAIPEErgAUIJPEAogQcIJfAAoQQeIJTAA4QSeIBQAg8QSuABQgk8QCiBBwgl8AChBB4glMADhBJ4gFACDxBK4AFCCTxAqE+lT2BttttvN/263e6fmc8ESPew3+9Ln0M3DF35kxjp1nBv+i83/brn4fvrj8Ue1qnvu4cxxwv8RLbbbzfH+x6Hoe86sYc1GRt4l2gqd/ymcfidgtgDlwh8Yw6Df3xZSPCBQwLfsHOre6EHus42yShz3AMA2iXwAKEEHiCUwAOEcpN1Qsd71gFK8kGnwrabTbfpH19//jy8dLvn54JnBNRi7AedXKIBCCXwldn0j912syl9GkAAgQcIJfAAoQQeIFRz2yQ/fz69qfzz52o34QCc1Vzgf/v5Z2fhu9HvOuEH1q3ZwB86jP2h4/ALPrAmrsEXtnl87J6Hl9KnAQSKWMF/PtNHK3ZgzZoN/GHUhRzgVLOBF3WAy1yDBwjV7Ao+jRutwNSs4Cux6R9fHxvsgWPAFAQeIJTAF/Zltzv5mss1wBRcgy/s+3Z78jX/oxMwBSt4gFACX9jzy8ub/5P1t/7MA9QAbiXwAKEEHiCUwAOEEviKHG6PHDxrBxhJ4AFCCTxAKIEHCCXwFbMXHhjDowoKeu8xBdCq7a+n8y+efpbvj2uPXprr2GvHnzl2N/y48pvWQ+CBN94N9Q2h7C/Fcszz8yo7dvv16eLru7/reQMQ+IrZKsmh7a+nRVaz74baA05f9f9efn37+P8bwAT/Vj+6cW8WAl+Bw/3vniS5Ltv+aLV8YeL3L5dfv0qkF/H6BjnFv9XXcefysN+XXyU+vTy9PYkx182uHV/gmt3sx1473t952j97wmOvrQZZt93XH6N2WlSxgj/5lnDsSqOya3azH1vyz2707zxci/QH3BRrq2gWVEXgYWmjVs4iTSPsgwcIJfAAoQQeIJTAA4QSeIBQAg8QSuABQgk8QCiBBwgl8AChBB4glMADhBJ4gFACDxBK4AFCCTxAKIEHCCXwAKEEHiCUwAOEEniAUAIPEErgAUIJPEAogQcIJfAAoQQeIJTAA4QSeIBQAg8QSuABQgk8QCiBBwgl8AChBB4glMADhBJ4gFACDxBK4AFCCTxAKIEHCCXwAKEEHiCUwAOEEniAUAIPEErgAUIJPEAogQcIJfAAoQQeIJTAA4R62O/3pc8BgBlYwQOEEniAUAIPEErgAUIJPEAogQcIJfAAoQQeIJTAA4QSeIBQAg8QSuABQgk8QCiBBwgl8AChBB4glMADhBJ4gFACDxBK4AFCCTxAKIEHCCXwAKH+A2RFZ22qil3LAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def update_scene(num, frames, patch):\n",
    "    patch.set_data(frames[num])\n",
    "    return patch\n",
    "\n",
    "env = gym.make(\"BipedalWalker-v2\")\n",
    "fs = []\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    init.run()\n",
    "    obs = env.reset()\n",
    "    for step in range(1000):\n",
    "        \n",
    "        fs.append(env.render(mode=\"rgb_array\"))\n",
    "        action = possible_actions[action_index.eval(feed_dict={X: obs.reshape(1, n_inputs)})]\n",
    "        obs, reward, done, info = env.step(action[0])\n",
    "        if done:\n",
    "            break\n",
    "env.close()\n",
    "\n",
    "plt.close() \n",
    "fig = plt.figure()\n",
    "patch = plt.imshow(fs[0])\n",
    "plt.axis('off')\n",
    "video=animation.FuncAnimation(fig, update_scene, fargs=(fs, patch), frames=len(fs), repeat=False, interval=50)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1000/1000"
     ]
    }
   ],
   "source": [
    "n_games_per_update = 10\n",
    "n_max_steps = 1000\n",
    "n_iterations = 1000\n",
    "\n",
    "#n_max_steps = 10\n",
    "#n_iterations = 10\n",
    "save_iterations = 10\n",
    "discount_rate = 0.95\n",
    "\n",
    "def d_rewards(rewards, discount_rate):\n",
    "    discounted_r = np.zeros(len(rewards))\n",
    "    cumulative_rewards = 0\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        cumulative_rewards = rewards[step] + cumulative_rewards * discount_rate\n",
    "        discounted_r[step] = cumulative_rewards\n",
    "    return discounted_r\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for iteration in range(n_iterations):\n",
    "        print(\"\\rIteration: {}/{}\".format(iteration + 1, n_iterations), end=\"\")\n",
    "        all_rewards = []\n",
    "        all_gradients = []\n",
    "        for game in range(n_games_per_update):\n",
    "            current_rewards = []\n",
    "            current_gradients = []\n",
    "            obs = env.reset()\n",
    "            for step in range(n_max_steps):\n",
    "                action_index_val, gradients_val = sess.run([action_index, gradients], feed_dict={X: obs.reshape(1, n_inputs)})\n",
    "                action = possible_actions[action_index_val]\n",
    "                obs, reward, done, info = env.step(action[0])\n",
    "                current_rewards.append(reward)\n",
    "                current_gradients.append(gradients_val)\n",
    "                if done:\n",
    "                    break\n",
    "            all_rewards.append(current_rewards)\n",
    "            all_gradients.append(current_gradients)\n",
    "\n",
    "    \n",
    "        all_discounted_rewards = [d_rewards(rewards, discount_rate) for rewards in all_rewards]\n",
    "        flat_rewards = np.concatenate(all_discounted_rewards)\n",
    "        r_mean = flat_rewards.mean()\n",
    "        r_std = flat_rewards.std()\n",
    "        all_rewards=[(discounted_rewards - r_mean)/r_std for discounted_rewards in all_discounted_rewards]\n",
    "\n",
    "        feed_dict = {}\n",
    "        for var_index, gradient_placeholder in enumerate(gradient_placeholders):\n",
    "            mean_gradients = np.mean([reward * all_gradients[game_index][step][var_index]\n",
    "                                      for game_index, rewards in enumerate(all_rewards)\n",
    "                                          for step, reward in enumerate(rewards)], axis=0)\n",
    "            feed_dict[gradient_placeholder] = mean_gradients\n",
    "        sess.run(training_op, feed_dict=feed_dict)\n",
    "        if iteration % save_iterations == 0:\n",
    "            saver.save(sess, \"./walker_pg.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./walker_pg.ckpt\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make(\"BipedalWalker-v2\")\n",
    "fs = []\n",
    "with tf.Session() as sess:\n",
    "        \n",
    "    saver.restore(sess, \"./walker_pg.ckpt\")\n",
    "    obs = env.reset()\n",
    "    for step in range(1000):\n",
    "        \n",
    "        fs.append(env.render(mode=\"rgb_array\"))\n",
    "        \n",
    "        action = possible_actions[action_index.eval(feed_dict={X: obs.reshape(1, n_inputs)})]\n",
    "        obs, reward, done, info = env.step(action[0])\n",
    "        if done:\n",
    "            break\n",
    "env.close()\n",
    "\n",
    "plt.close() \n",
    "fig = plt.figure()\n",
    "patch = plt.imshow(fs[0])\n",
    "plt.axis('off')\n",
    "video=animation.FuncAnimation(fig, update_scene, fargs=(fs, patch), frames=len(fs), repeat=False, interval=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
